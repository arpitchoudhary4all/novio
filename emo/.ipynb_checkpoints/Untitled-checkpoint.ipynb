{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-98daeee94f15>, line 466)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-98daeee94f15>\"\u001b[0;36m, line \u001b[0;32m466\u001b[0m\n\u001b[0;31m    main(sys.argv[1:])\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from faces import FaceDetector\n",
    "from data import FaceData\n",
    "from gabor import GaborBank\n",
    "from emotions import EmotionsDetector\n",
    "\n",
    "#---------------------------------------------\n",
    "class VideoData:\n",
    "    \"\"\"\n",
    "    Helper class to present the detected face region, landmarks and emotions.\n",
    "    \"\"\"\n",
    "\n",
    "    #-----------------------------------------\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Class constructor.\n",
    "        \"\"\"\n",
    "\n",
    "        self._faceDet = FaceDetector()\n",
    "        '''\n",
    "        The instance of the face detector.\n",
    "        '''\n",
    "\n",
    "        self._bank = GaborBank()\n",
    "        '''\n",
    "        The instance of the bank of Gabor filters.\n",
    "        '''\n",
    "\n",
    "        self._emotionsDet = EmotionsDetector()\n",
    "        '''\n",
    "        The instance of the emotions detector.\n",
    "        '''\n",
    "\n",
    "        self._face = FaceData()\n",
    "        '''\n",
    "        Data of the last face detected.\n",
    "        '''\n",
    "\n",
    "        self._emotions = OrderedDict()\n",
    "        '''\n",
    "        Data of the last emotions detected.\n",
    "        '''\n",
    "\n",
    "    #-----------------------------------------\n",
    "    def detect(self, frame):\n",
    "        \"\"\"\n",
    "        Detects a face and the prototypic emotions on the given frame image.\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame: numpy.ndarray\n",
    "            Image where to perform the detections from.\n",
    "        Returns\n",
    "        -------\n",
    "        ret: bool\n",
    "            Indication of success or failure.\n",
    "        \"\"\"\n",
    "\n",
    "        ret, face = self._faceDet.detect(frame)\n",
    "        if ret:\n",
    "            self._face = face\n",
    "\n",
    "            # Crop just the face region\n",
    "            frame, face = face.crop(frame)\n",
    "\n",
    "            # Filter it with the Gabor bank\n",
    "            responses = self._bank.filter(frame)\n",
    "\n",
    "            # Detect the prototypic emotions based on the filter responses\n",
    "            self._emotions = self._emotionsDet.detect(face, responses)\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            self._face = None\n",
    "            return False\n",
    "\n",
    "    #-----------------------------------------\n",
    "    def draw(self, frame):\n",
    "        \"\"\"\n",
    "        Draws the detected data of the given frame image.\n",
    "        Parameters\n",
    "        ----------\n",
    "        frame: numpy.ndarray\n",
    "            Image where to draw the information to.\n",
    "        \"\"\"\n",
    "        # Font settings\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        scale = 0.5\n",
    "        thick = 1\n",
    "        glow = 3 * thick\n",
    "\n",
    "        # Color settings\n",
    "        black = (0, 0, 0)\n",
    "        white = (255, 255, 255)\n",
    "        yellow = (0, 255, 255)\n",
    "        red = (0, 0, 255)\n",
    "\n",
    "        empty = True\n",
    "\n",
    "        # Plot the face landmarks and face distance\n",
    "        x = 5\n",
    "        y = 0\n",
    "        w = int(frame.shape[1]* 0.2)\n",
    "        try:\n",
    "            face = self._face\n",
    "            empty = face.isEmpty()\n",
    "            face.draw(frame)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Plot the emotion probabilities\n",
    "        try:\n",
    "            emotions = self._emotions\n",
    "            if empty:\n",
    "                labels = []\n",
    "                values = []\n",
    "            else:\n",
    "                labels = list(emotions.keys())\n",
    "                values = list(emotions.values())\n",
    "                bigger = labels[values.index(max(values))]\n",
    "\n",
    "                # Draw the header\n",
    "                text = 'emotions'\n",
    "                size, _ = cv2.getTextSize(text, font, scale, thick)\n",
    "                y += size[1] + 20\n",
    "\n",
    "                cv2.putText(frame, text, (x, y), font, scale, black, glow)\n",
    "                cv2.putText(frame, text, (x, y), font, scale, yellow, thick)\n",
    "\n",
    "                y += 5\n",
    "                cv2.line(frame, (x,y), (x+w,y), black, 1)\n",
    "\n",
    "            size, _ = cv2.getTextSize('happiness', font, scale, thick)\n",
    "            t = size[0] + 20\n",
    "            w = 150\n",
    "            h = size[1]\n",
    "            for l, v in zip(labels, values):\n",
    "                lab = '{}:'.format(l)\n",
    "                val = '{:.2f}'.format(v)\n",
    "                size, _ = cv2.getTextSize(l, font, scale, thick)\n",
    "\n",
    "                # Set a red color for the emotion with bigger probability\n",
    "                color = red if l == bigger else yellow\n",
    "\n",
    "                y += size[1] + 15\n",
    "\n",
    "                p1 = (x+t, y-size[1]-5)\n",
    "                p2 = (x+t+w, y-size[1]+h+5)\n",
    "                cv2.rectangle(frame, p1, p2, black, 1)\n",
    "\n",
    "                # Draw the filled rectangle proportional to the probability\n",
    "                p2 = (p1[0] + int((p2[0] - p1[0]) * v), p2[1])\n",
    "                cv2.rectangle(frame, p1, p2, color, -1)\n",
    "                cv2.rectangle(frame, p1, p2, black, 1)\n",
    "\n",
    "                # Draw the emotion label\n",
    "                cv2.putText(frame, lab, (x, y), font, scale, black, glow)\n",
    "                cv2.putText(frame, lab, (x, y), font, scale, color, thick)\n",
    "\n",
    "                # Draw the value of the emotion probability\n",
    "                cv2.putText(frame, val, (x+t+5, y), font, scale, black, glow)\n",
    "                cv2.putText(frame, val, (x+t+5, y), font, scale, white, thick)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "#---------------------------------------------\n",
    "def main(argv):\n",
    "    \"\"\"\n",
    "    Main entry of this script.\n",
    "    Parameters\n",
    "    ------\n",
    "    argv: list of str\n",
    "        Arguments received from the command line.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the command line\n",
    "    args = parseCommandLine(argv)\n",
    "\n",
    "    # Loads the video or starts the webcam\n",
    "    if args.source == 'cam':\n",
    "        video = cv2.VideoCapture(args.id)\n",
    "        if not video.isOpened():\n",
    "            print('Error opening webcam of id {}'.format(args.id))\n",
    "            sys.exit(-1)\n",
    "\n",
    "        fps = 0\n",
    "        frameCount = 0\n",
    "        sourceName = 'Webcam #{}'.format(args.id)\n",
    "    else:\n",
    "        video = cv2.VideoCapture(args.file)\n",
    "        if not video.isOpened():\n",
    "            print('Error opening video file {}'.format(args.file))\n",
    "            sys.exit(-1)\n",
    "\n",
    "        fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "        frameCount = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        sourceName = args.file\n",
    "\n",
    "    # Force HD resolution (if the video was not recorded in this resolution or\n",
    "    # if the camera does not support it, the frames will be stretched to fit it)\n",
    "    # The intention is just to standardize the input (and make the help window\n",
    "    # work as intended)\n",
    "    video.set(cv2.CAP_PROP_FRAME_WIDTH, 1280);\n",
    "    video.set(cv2.CAP_PROP_FRAME_HEIGHT, 720);\n",
    "\n",
    "    # Create the helper class\n",
    "    data = VideoData()\n",
    "\n",
    "    # Text settings\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 1\n",
    "    thick = 1\n",
    "    glow = 3 * thick\n",
    "\n",
    "    # Color settings\n",
    "    color = (255, 255, 255)\n",
    "\n",
    "    paused = False\n",
    "    frameNum = 0\n",
    "\n",
    "    # Process the video input\n",
    "    while True:\n",
    "\n",
    "        if not paused:\n",
    "            start = datetime.now()\n",
    "\n",
    "        ret, img = video.read()\n",
    "        if ret:\n",
    "            frame = img.copy()\n",
    "        else:\n",
    "            paused = True\n",
    "\n",
    "        drawInfo(frame, frameNum, frameCount, paused, fps, args.source)\n",
    "\n",
    "        data.detect(frame)\n",
    "        data.draw(frame)\n",
    "\n",
    "        cv2.imshow(sourceName, frame)\n",
    "\n",
    "        if paused:\n",
    "            key = cv2.waitKey(0)\n",
    "        else:\n",
    "            end = datetime.now()\n",
    "            delta = (end - start)\n",
    "            if fps != 0:\n",
    "                delay = int(max(1, ((1 / fps) - delta.total_seconds()) * 1000))\n",
    "            else:\n",
    "                delay = 1\n",
    "\n",
    "            key = cv2.waitKey(delay)\n",
    "\n",
    "        if key == ord('q') or key == ord('Q') or key == 27:\n",
    "            break\n",
    "        elif key == ord('p') or key == ord('P'):\n",
    "            paused = not paused\n",
    "        elif args.source == 'video' and (key == ord('r') or key == ord('R')):\n",
    "            frameNum = 0\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        elif args.source == 'video' and paused and key == 2424832: # Left key\n",
    "            frameNum -= 1\n",
    "            if frameNum < 0:\n",
    "                frameNum = 0\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        elif args.source == 'video' and paused and key == 2555904: # Right key\n",
    "            frameNum += 1\n",
    "            if frameNum >= frameCount:\n",
    "                frameNum = frameCount - 1\n",
    "        elif args.source == 'video' and key == 2162688: # Pageup key\n",
    "            frameNum -= (fps * 10)\n",
    "            if frameNum < 0:\n",
    "                frameNum = 0\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        elif args.source == 'video' and key == 2228224: # Pagedown key\n",
    "            frameNum += (fps * 10)\n",
    "            if frameNum >= frameCount:\n",
    "                frameNum = frameCount - 1\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, frameNum)\n",
    "        elif key == 7340032: # F1\n",
    "            showHelp(sourceName, frame.shape)\n",
    "\n",
    "        if not paused:\n",
    "            frameNum += 1\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#---------------------------------------------\n",
    "def drawInfo(frame, frameNum, frameCount, paused, fps, source):\n",
    "    \"\"\"\n",
    "    Draws text info related to the given frame number into the frame image.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image: numpy.ndarray\n",
    "        Image data where to draw the text info.\n",
    "    frameNum: int\n",
    "        Number of the frame of which to drawn the text info.\n",
    "    frameCount: int\n",
    "        Number total of frames in the video.\n",
    "    paused: bool\n",
    "        Indication if the video is paused or not.\n",
    "    fps: int\n",
    "        Frame rate (in frames per second) of the video for time calculation.\n",
    "    source: str\n",
    "        Source of the input images (either \"video\" or \"cam\").\n",
    "    \"\"\"\n",
    "\n",
    "    # Font settings\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 0.5\n",
    "    thick = 1\n",
    "    glow = 3 * thick\n",
    "\n",
    "    # Color settings\n",
    "    black = (0, 0, 0)\n",
    "    yellow = (0, 255, 255)\n",
    "\n",
    "    # Print the current frame number and timestamp\n",
    "    if source == 'video':\n",
    "        text = 'Frame: {:d}/{:d} {}'.format(frameNum, frameCount - 1,\n",
    "                                            '(paused)' if paused else '')\n",
    "    else:\n",
    "        text = 'Frame: {:d} {}'.format(frameNum, '(paused)' if paused else '')\n",
    "    size, _ = cv2.getTextSize(text, font, scale, thick)\n",
    "    x = 5\n",
    "    y = frame.shape[0] - 2 * size[1]\n",
    "    cv2.putText(frame, text, (x, y), font, scale, black, glow)\n",
    "    cv2.putText(frame, text, (x, y), font, scale, yellow, thick)\n",
    "\n",
    "    if source == 'video':\n",
    "        timestamp = datetime.min + timedelta(seconds=(frameNum / fps))\n",
    "        elapsedTime = datetime.strftime(timestamp, '%H:%M:%S')\n",
    "        timestamp = datetime.min + timedelta(seconds=(frameCount / fps))\n",
    "        totalTime = datetime.strftime(timestamp, '%H:%M:%S')\n",
    "\n",
    "        text = 'Time: {}/{}'.format(elapsedTime, totalTime)\n",
    "        size, _ = cv2.getTextSize(text, font, scale, thick)\n",
    "        y = frame.shape[0] - 5\n",
    "        cv2.putText(frame, text, (x, y), font, scale, black, glow)\n",
    "        cv2.putText(frame, text, (x, y), font, scale, yellow, thick)\n",
    "\n",
    "    # Print the help message\n",
    "    text = 'Press F1 for help'\n",
    "    size, _ = cv2.getTextSize(text, font, scale, thick)\n",
    "    x = frame.shape[1] - size[0] - 5\n",
    "    y = frame.shape[0] - size[1] + 5\n",
    "    cv2.putText(frame, text, (x, y), font, scale, black, glow)\n",
    "    cv2.putText(frame, text, (x, y), font, scale, yellow, thick)\n",
    "\n",
    "#---------------------------------------------\n",
    "def showHelp(windowTitle, shape):\n",
    "    \"\"\"\n",
    "    Displays an image with helping text.\n",
    "    Parameters\n",
    "    ----------\n",
    "    windowTitle: str\n",
    "        Title of the window where to display the help\n",
    "    shape: tuple\n",
    "        Height and width of the window to create the help image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Font settings\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    scale = 1.0\n",
    "    thick = 1\n",
    "\n",
    "    # Color settings\n",
    "    black = (0, 0, 0)\n",
    "    red = (0, 0, 255)\n",
    "\n",
    "    # Create the background image\n",
    "    image = np.ones((shape[0], shape[1], 3)) * 255\n",
    "\n",
    "    # The help text is printed in one line per item in this list\n",
    "    helpText = [\n",
    "    'Controls:',\n",
    "    '-----------------------------------------------',\n",
    "    '[q] or [ESC]: quits from the application.',\n",
    "    '[p]: toggles paused/playing the video/webcam input.',\n",
    "    '[r]: restarts the video playback (video input only).',\n",
    "    '[left/right arrow]: displays the previous/next frame (video input only).',\n",
    "    '[page-up/down]: rewinds/fast forwards by 10 seconds (video input only).',\n",
    "    ' ',\n",
    "    ' ',\n",
    "    'Press any key to close this window...'\n",
    "    ]\n",
    "\n",
    "    # Print the controls help text\n",
    "    xCenter = image.shape[1] // 2\n",
    "    yCenter = image.shape[0] // 2\n",
    "\n",
    "    margin = 20 # between-lines margin in pixels\n",
    "    textWidth = 0\n",
    "    textHeight = margin * (len(helpText) - 1)\n",
    "    lineHeight = 0\n",
    "    for line in helpText:\n",
    "        size, _ = cv2.getTextSize(line, font, scale, thick)\n",
    "        textHeight += size[1]\n",
    "        textWidth = size[0] if size[0] > textWidth else textWidth\n",
    "        lineHeight = size[1] if size[1] > lineHeight else lineHeight\n",
    "\n",
    "    x = xCenter - textWidth // 2\n",
    "    y = yCenter - textHeight // 2\n",
    "\n",
    "    for line in helpText:\n",
    "        cv2.putText(image, line, (x, y), font, scale, black, thick * 3)\n",
    "        cv2.putText(image, line, (x, y), font, scale, red, thick)\n",
    "        y += margin + lineHeight\n",
    "\n",
    "    # Show the image and wait for a key press\n",
    "    cv2.imshow(windowTitle, image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "#---------------------------------------------\n",
    "def parseCommandLine(argv):\n",
    "    \"\"\"\n",
    "    Parse the command line of this utility application.\n",
    "    This function uses the argparse package to handle the command line\n",
    "    arguments. In case of command line errors, the application will be\n",
    "    automatically terminated.\n",
    "    Parameters\n",
    "    ------\n",
    "    argv: list of str\n",
    "        Arguments received from the command line.\n",
    "    Returns\n",
    "    ------\n",
    "    object\n",
    "        Object with the parsed arguments as attributes (refer to the\n",
    "        documentation of the argparse package for details)\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Tests the face and emotion '\n",
    "                                        'detector on a video file input.')\n",
    "\n",
    "    parser.add_argument('source', nargs='?', const='Yes',\n",
    "                        choices=['video', 'cam'], default='cam',\n",
    "                        help='Indicate the source of the input images for '\n",
    "                        'the detectors: \"video\" for a video file or '\n",
    "                        '\"cam\" for a webcam. The default is \"cam\".')\n",
    "\n",
    "    parser.add_argument('-f', '--file', metavar='<name>',\n",
    "                        help='Name of the video file to use, if the source is '\n",
    "                        '\"video\". The supported formats depend on the codecs '\n",
    "                        'installed in the operating system.')\n",
    "\n",
    "    parser.add_argument('-i', '--id', metavar='<number>', default=0, type=int,\n",
    "                        help='Numerical id of the webcam to use, if the source '\n",
    "                        'is \"cam\". The default is 0.')\n",
    "\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.source == 'video' and args.file is None:\n",
    "        parser.error('-f is required when source is \"video\"')\n",
    "\n",
    "    return args\n",
    "\n",
    "#---------------------------------------------\n",
    "# namespace verification for invoking main\n",
    "#---------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
